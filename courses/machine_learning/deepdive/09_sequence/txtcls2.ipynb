{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Text Classification using TensorFlow on Cloud ML Engine (using pretrained embedding) </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating datasets for Machine Learning using BigQuery\n",
    "<li> Creating a text classification model using the high-level Estimator API and a pre-trained embedding. (this is the difference vs <a href=\"txtcls1.ipyb\"> txtcls1.ipynb </a>)\n",
    "<li> Training on Cloud ML Engine\n",
    "<li> Deploying model\n",
    "<li> Predicting with model\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to look at the title of a newspaper article and figure out whether the article came from the New York Times or from TechCrunch. Look at <a href=\"txtcls1.ipyb\"> txtcls1.ipynb </a> for a solution that learns words embeddings as part of the problem itself. In this notebook, I will show how to use a pretrained embedding instead.\n",
    "\n",
    "<h2> Data exploration and preprocessing in BigQuery </h2>\n",
    "<p>\n",
    "See <a href=\"txtcls1.ipyb\"> txtcls1.ipynb </a> for an explanation. Here, I simply repeat the key steps to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "query=\"\"\"\n",
    "SELECT source, LOWER(REGEXP_REPLACE(title, '[^a-zA-Z0-9 $.-]', ' ')) AS title FROM\n",
    "(SELECT\n",
    "  ARRAY_REVERSE(SPLIT(REGEXP_EXTRACT(url, '.*://(.[^/]+)/'), '.'))[OFFSET(1)] AS source,\n",
    "  title\n",
    "FROM\n",
    "  `bigquery-public-data.hacker_news.stories`\n",
    "WHERE\n",
    "  REGEXP_CONTAINS(REGEXP_EXTRACT(url, '.*://(.[^/]+)/'), '.com$')\n",
    "  AND LENGTH(title) > 10\n",
    ")\n",
    "WHERE (source = 'github' OR source = 'nytimes' OR source = 'techcrunch')\n",
    "\"\"\"\n",
    "\n",
    "traindf = bq.Query(query + \" AND MOD(ABS(FARM_FINGERPRINT(title)),4) > 0\").execute().result().to_dataframe()\n",
    "evaldf  = bq.Query(query + \" AND MOD(ABS(FARM_FINGERPRINT(title)),4) = 0\").execute().result().to_dataframe()\n",
    "\n",
    "import os, shutil\n",
    "DATADIR='data/txtcls2'\n",
    "shutil.rmtree(DATADIR, ignore_errors=True)\n",
    "os.makedirs(DATADIR)\n",
    "traindf.to_csv( os.path.join(DATADIR,'train.csv'), header=False, index=False, encoding='utf-8', sep='\\t')\n",
    "evaldf.to_csv( os.path.join(DATADIR,'eval.csv'), header=False, index=False, encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gsutil cp data/txtcls2/*.csv gs://${BUCKET}/txtcls2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained embedding\n",
    "\n",
    "To provide words as inputs to a neural network, we have to convert words to numbers. Ideally, we want related words to have numbers that are close to each other. This is what an embedding (such as word2vec) does. Here, I'll use the <a href=\"https://nlp.stanford.edu/projects/glove/\">GloVe</a> embedding from Stanford just because, at 160MB, it is smaller than <a href=\"https://code.google.com/archive/p/word2vec/\">word2vec</a> from Google (1.5 GB).\n",
    "<p>\n",
    "For testing purposes, I will also create a smaller file, consisting of the 1000 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "unzip -p glove.6B.zip glove.6B.50d.txt | gzip > pretrained_embedding.txt.gz\n",
    "#rm glove.6B.zip\n",
    "\n",
    "rm subset_embedding.txt*\n",
    "zcat pretrained_embedding.txt.gz | head -1000 > subset_embedding.txt\n",
    "gzip subset_embedding.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "gzip: stdout: Broken pipe\n",
      "Copying file://pretrained_embedding.txt.gz [Content-Type=text/plain]...\n",
      "/ [0 files][    0.0 B/ 66.0 MiB]                                                \r",
      "/ [0 files][792.0 KiB/ 66.0 MiB]                                                \r",
      "-\r",
      "\\\r",
      "\\ [0 files][  2.3 MiB/ 66.0 MiB]                                                \r",
      "|\r",
      "/\r",
      "/ [0 files][  4.1 MiB/ 66.0 MiB]                                                \r",
      "-\r",
      "- [0 files][  5.2 MiB/ 66.0 MiB]                                                \r",
      "\\\r",
      "|\r",
      "| [0 files][  7.2 MiB/ 66.0 MiB]                                                \r",
      "/\r",
      "/ [0 files][  8.3 MiB/ 66.0 MiB]                                                \r",
      "-\r",
      "\\\r",
      "\\ [0 files][ 10.3 MiB/ 66.0 MiB]                                                \r",
      "|\r",
      "/\r",
      "/ [0 files][ 12.9 MiB/ 66.0 MiB]                                                \r",
      "-\r",
      "- [0 files][ 15.5 MiB/ 66.0 MiB]                                                \r",
      "\\\r",
      "|\r",
      "| [0 files][ 16.8 MiB/ 66.0 MiB]    1.9 MiB/s                                   \r",
      "/\r",
      "-\r",
      "- [0 files][ 19.3 MiB/ 66.0 MiB]    2.0 MiB/s                                   \r",
      "\\\r",
      "\\ [0 files][ 22.2 MiB/ 66.0 MiB]    2.1 MiB/s                                   \r",
      "|\r",
      "/\r",
      "/ [0 files][ 25.3 MiB/ 66.0 MiB]    2.2 MiB/s                                   \r",
      "-\r",
      "\\\r",
      "\\ [0 files][ 28.6 MiB/ 66.0 MiB]    2.5 MiB/s                                   \r",
      "|\r",
      "| [0 files][ 32.2 MiB/ 66.0 MiB]    2.8 MiB/s                                   \r",
      "/\r",
      "-\r",
      "- [0 files][ 36.4 MiB/ 66.0 MiB]    3.1 MiB/s                                   \r",
      "\\\r",
      "|\r",
      "| [0 files][ 40.0 MiB/ 66.0 MiB]    3.2 MiB/s                                   \r",
      "/\r",
      "/ [0 files][ 44.1 MiB/ 66.0 MiB]    3.4 MiB/s                                   \r",
      "-\r",
      "\\\r",
      "\\ [0 files][ 48.0 MiB/ 66.0 MiB]    3.4 MiB/s                                   \r",
      "|\r",
      "/\r",
      "/ [0 files][ 50.8 MiB/ 66.0 MiB]    3.2 MiB/s                                   \r",
      "-\r",
      "- [0 files][ 53.6 MiB/ 66.0 MiB]    3.0 MiB/s                                   \r",
      "\\\r",
      "|\r",
      "| [0 files][ 56.2 MiB/ 66.0 MiB]    2.8 MiB/s                                   \r",
      "/\r",
      "/ [0 files][ 58.8 MiB/ 66.0 MiB]    2.5 MiB/s                                   \r",
      "-\r",
      "\\\r",
      "\\ [0 files][ 62.4 MiB/ 66.0 MiB]    2.5 MiB/s                                   \r",
      "|\r",
      "/\r",
      "/ [0 files][ 65.2 MiB/ 66.0 MiB]    2.5 MiB/s                                   \r",
      "/ [1 files][ 66.0 MiB/ 66.0 MiB]    2.2 MiB/s                                   \r",
      "-\r",
      "Copying file://subset_embedding.txt.gz [Content-Type=text/plain]...\n",
      "- [1 files][ 66.0 MiB/ 66.1 MiB]    2.2 MiB/s                                   \r",
      "- [2 files][ 66.1 MiB/ 66.1 MiB]    2.1 MiB/s                                   \r",
      "\\\r\n",
      "Operation completed over 2 objects/66.1 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "zcat subset_embedding.txt.gz | head -1\n",
    "gsutil cp *_embedding.txt.gz gs://${BUCKET}/txtcls2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gsutil ls -l gs://${BUCKET}/txtcls2/*.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PADWORD = 'ZYXW'\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "class Word2Vec:\n",
    "  '''\n",
    "  vocab, embeddings\n",
    "  '''\n",
    "  def vocab_size(self):\n",
    "    return len(self.vocab)\n",
    "  \n",
    "  def embed_dim(self):\n",
    "    return len(self.embeddings[0])\n",
    "  \n",
    "  def __init__(self, filename):\n",
    "    import gzip, StringIO\n",
    "    import numpy as np\n",
    "    self.vocab = [PADWORD]\n",
    "    self.embeddings = [0]\n",
    "    with file_io.FileIO(filename, mode='rb') as f:\n",
    "      compressedFile = StringIO.StringIO(f.read())\n",
    "      decompressedFile = gzip.GzipFile(fileobj=compressedFile)\n",
    "      for line in decompressedFile:\n",
    "        pieces = line.split()\n",
    "        self.vocab.append(pieces[0])\n",
    "        self.embeddings.append(np.asarray(pieces[1:], dtype='float32'))\n",
    "    self.embeddings[0] = np.zeros_like(self.embeddings[1])\n",
    "    self.vocab.append('') # for out-of-value words\n",
    "    self.embeddings.append(np.ones_like(self.embeddings[1]))\n",
    "    self.embeddings = np.array(self.embeddings)\n",
    "    print('Loaded {}D vectors for {} words from {}'.format(self.embed_dim(), self.vocab_size(), filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50D vectors for 1002 words from subset_embedding.txt.gz\n",
      "(1002, 50)\n"
     ]
    }
   ],
   "source": [
    "#wv = Word2Vec('gs://{}/txtcls2/pretrained_embedding.txt.gz'.format(BUCKET))\n",
    "wv = Word2Vec('subset_embedding.txt.gz'.format(BUCKET))\n",
    "print wv.embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> TensorFlow code </h2>\n",
    "\n",
    "Please explore the code in this <a href=\"txtcls2/trainer\">directory</a> -- <a href=\"txtcls2/trainer/model.py\">model.py</a> contains the key TensorFlow model and <a href=\"txtcls2/trainer/task.py\">task.py</a> has a main() that launches off the training job.\n",
    "\n",
    "The following cells should give you an idea of what the model code does. The idea is to load up the embedding file and get vectors corresponding to the words in that file's vocabulary.  For example \"the\" might be mapped to a 50D vector.  Now, whenever we see \"the\" in the input document, we need to replace it by the 50D vector.\n",
    "The method that does this:\n",
    "<pre>\n",
    "tf.nn.embedding_lookup\n",
    "</pre>\n",
    "requires the *index* of the word \"the\" in the original file (perhaps that index=1). To find the index, we will use VocabularyProcessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "numbers= [[ 0.13403     0.89178002 -0.76761001 -0.64183998  0.86203998  1.31219995\n",
      "  -0.64017999  0.82067001  0.32782999  0.021457   -0.095194    0.40825\n",
      "  -0.63602    -0.018275    0.69708002 -0.29530999 -1.19120002 -0.23897\n",
      "   0.34340999 -0.33195999  0.23702     1.83640003  0.12295    -0.18624\n",
      "   0.86502999 -2.63599992 -0.7791      0.20299999  0.18985    -0.79896998\n",
      "   2.98819995  0.44336    -0.28367001 -0.19588     0.061875    0.38558\n",
      "  -0.027622    0.71846998  0.17156    -1.21679997  0.081636    0.17293\n",
      "  -0.31718001 -0.37039     0.18977    -0.89174998  0.18492    -1.62510002\n",
      "   0.039134   -0.10279   ]\n",
      " [ 0.79667002 -0.42120001  0.48504999  0.40887001 -0.073664   -0.21618\n",
      "  -0.83293003  0.20614     0.31885001 -0.39559999 -0.096698   -0.54991001\n",
      "  -0.53323001 -0.6437      1.01269996 -0.23283    -1.18599999 -0.78666002\n",
      "  -0.33329001 -0.28738999  0.60349     0.54689997  0.77043998 -0.40391999\n",
      "  -0.011623   -1.56649995 -0.75793999  0.3075     -0.59415001  0.57292998\n",
      "   3.04690003 -0.48712999  0.51389003 -0.88178998 -0.1109     -0.19412\n",
      "  -0.064599   -0.63158    -0.14518    -0.021792    0.046025    0.28184\n",
      "   0.44459999 -0.21606     0.81748003 -0.47946    -0.54101998  1.7342\n",
      "   0.45771    -0.44523001]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]] (4, 5, 50)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import lookup\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "\n",
    "print tf.__version__\n",
    "MAX_DOCUMENT_LENGTH = 5  \n",
    "\n",
    "# raw input\n",
    "lines = ['Some title', 'A longer title', 'An even longer title', 'This is longer than doc length']\n",
    "lines = [line.lower() for line in lines]\n",
    "#lines = tf.constant(lines)  # vocabprocessor doesn't work\n",
    "\n",
    "# we first create word-ids for each of the words in the glove embedding file\n",
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "vocab_processor.fit(wv.vocab)  # word to word-id\n",
    "wordid_to_embed = tf.convert_to_tensor(wv.embeddings) # word-id to embedding\n",
    "\n",
    "# take lines of input and find word-ids; then lookup the embedding for each word-id\n",
    "tensorids = np.array(list(vocab_processor.transform(lines)))\n",
    "numbers = tf.nn.embedding_lookup(wordid_to_embed, tensorids)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  print \"numbers=\", numbers.eval()[0], numbers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, [as pointed out by Dennis Murray](https://stackoverflow.com/questions/35687678/using-a-pre-trained-word-embedding-word2vec-or-glove-in-tensorflow), tf.constants are not memory efficient. To avoid storing multiple copies of the wordid_to_embed tensor, we should use a Variable. \n",
    "<p>\n",
    "Also, although the VocabularyProcessor has that convenient transform() method, it is pure Python and can not handle Tensors. Our \"lines\" will actually be a tensor in real-life. So, we have to use index_table and do a lookup using that ...  This code also differs in how we handle \"out-of-bucket\" words -- we use ones (because PADWORD is mapped to zeros) whereas vocab processor uses zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "embeds= [[  9.28709984e-01  -1.08340003e-01   2.14969993e-01  -5.02370000e-01\n",
      "    1.03790000e-01   2.27280006e-01  -5.41980028e-01  -2.90080011e-01\n",
      "   -6.46070004e-01   1.26640007e-01  -4.14869994e-01  -2.93430001e-01\n",
      "    3.68550003e-01  -4.17329997e-01   6.91160023e-01   6.73409998e-02\n",
      "    1.97150007e-01  -3.04649994e-02  -2.17230007e-01  -1.22379994e+00\n",
      "    9.54690017e-03   1.95940003e-01   5.65949976e-01  -6.74730018e-02\n",
      "    5.92079982e-02  -1.39090002e+00  -8.92750025e-01  -1.35460004e-01\n",
      "    1.62000000e-01  -4.02099997e-01   4.16440010e+00   3.78160000e-01\n",
      "    1.57969996e-01  -4.88920003e-01   2.31309995e-01   2.32580006e-01\n",
      "   -2.53140002e-01  -1.99770004e-01  -1.22579999e-01   1.56200007e-01\n",
      "   -3.19950014e-01   3.83139998e-01   4.72660005e-01   8.76999974e-01\n",
      "    3.22230011e-01   1.32919999e-03  -4.98600006e-01   5.55800021e-01\n",
      "   -7.03589976e-01  -5.26929975e-01]\n",
      " [ -1.23829997e+00   9.94870007e-01  -7.36769974e-01   1.07729995e+00\n",
      "    2.54099995e-01   8.17380026e-02   1.71859995e-01   5.98119974e-01\n",
      "   -4.36639994e-01   2.95870006e-02   2.88109988e-01   4.22540009e-01\n",
      "   -1.42550004e+00  -4.15740013e-01   1.11290002e+00  -4.15289998e-01\n",
      "   -5.76269999e-02  -2.32109994e-01  -1.25600004e+00   5.19549996e-02\n",
      "   -6.96030021e-01  -5.83909988e-01   4.10780013e-02   2.94380009e-01\n",
      "    3.43220010e-02  -1.72819996e+00  -1.19000006e+00  -8.35300028e-01\n",
      "   -5.44059992e-01  -1.67009994e-01   2.53509998e+00   8.06529969e-02\n",
      "   -4.18489993e-01   3.09130013e-01   2.18779996e-01   4.78210002e-02\n",
      "    5.48640013e-01   8.98079991e-01  -1.01740003e+00  -1.59640002e+00\n",
      "    4.82549995e-01  -5.54600000e-01  -2.43799999e-01  -2.26220004e-02\n",
      "   -9.10660028e-01   1.49619997e-01   1.45300001e-01  -9.79659975e-01\n",
      "    2.02439994e-01  -3.60689998e-01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]] (?, 5, 50)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import lookup\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "\n",
    "print tf.__version__\n",
    "MAX_DOCUMENT_LENGTH = 5  \n",
    "\n",
    "# raw input\n",
    "lines = ['Some title', 'A longer title', 'An even longer title', 'This is longer than doc length']\n",
    "lines = [line.lower() for line in lines]\n",
    "lines = tf.constant(lines)\n",
    "\n",
    "wordid_to_embed = tf.Variable(tf.constant(0.0, shape=[wv.vocab_size(), wv.embed_dim()]), trainable=False, name=\"embedding\")\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [wv.vocab_size(), wv.embed_dim()])\n",
    "embedding_init = wordid_to_embed.assign(embedding_placeholder)\n",
    "  \n",
    "# take lines of input and find word-ids; then lookup the embedding for each word-id\n",
    "table = tf.contrib.lookup.index_table_from_tensor(tf.convert_to_tensor(wv.vocab[:-1]), num_oov_buckets=1)\n",
    "\n",
    "words = tf.string_split(lines)\n",
    "densewords = tf.sparse_tensor_to_dense(words, default_value=PADWORD)\n",
    "numbers = table.lookup(densewords)\n",
    "padding = tf.constant([[0,0],[0,MAX_DOCUMENT_LENGTH]])\n",
    "padded = tf.pad(numbers, padding)\n",
    "sliced = tf.slice(padded, [0,0], [-1, MAX_DOCUMENT_LENGTH])\n",
    "embeds = tf.nn.embedding_lookup(wordid_to_embed, sliced)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  tf.tables_initializer().run()\n",
    "  tf.get_default_session().run(embedding_init, feed_dict={embedding_placeholder: wv.embeddings})\n",
    "  print \"embeds=\", embeds.eval()[0], embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Word2Vec:\n",
      "  def vocab_size(self):\n",
      "  def embed_dim(self):\n",
      "  def __init__(self, filename):\n",
      "  def init(sess):\n",
      "  def get_embedding(self, lines):\n",
      "def init(hparams):\n",
      "def save_vocab(trainfile, txtcolname, outfilename):\n",
      "def read_dataset(hparams, prefix, batch_size=BATCH_SIZE):\n",
      "  def _input_fn():\n",
      "def get_embedding(hparams, titles, embed_size):\n",
      "def cnn_model(features, labels, mode, params):\n",
      "def serving_input_fn():\n",
      "def get_train(hparams):\n",
      "def get_valid(hparams, batch_size):\n",
      "def init_embedding_hooks(hparams):\n",
      "  class InitEmbeddingHook(tf.train.SessionRunHook):\n",
      "    def after_create_session(self, session, coord):\n",
      "def make_experiment_fn(output_dir, hparams):\n",
      "  def experiment_fn(output_dir):\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "grep -E \"def |class \" txtcls1/trainer/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the code works locally on a small dataset for a few steps. Because of the size of the graph, though, this will take a *long* time and may crash on smaller machines (it has to evaluate the graph five times and write out 5 checkpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "echo \"bucket=${BUCKET}\"\n",
    "rm -rf outputdir\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/txtcls1\n",
    "python -m trainer.task \\\n",
    "   --bucket=${BUCKET} \\\n",
    "   --output_dir=outputdir \\\n",
    "   --glove_embedding=gs://${BUCKET}/txtcls2/subset_embedding.txt.gz \\\n",
    "   --job-dir=./tmp --train_steps=200 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran it, I got a 37% accuracy after a few steps. Once the code works in standalone mode, you can run it on Cloud ML Engine. You can monitor the job from the GCP console in the Cloud Machine Learning Engine section.  Since we have 72,000 examples and batchsize=32, train_steps=36,000 essentially means 16 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/txtcls2/trained_model\n",
    "JOBNAME=txtcls_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gsutil cp txtcls1/trainer/*.py $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=$(pwd)/txtcls1/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC_GPU \\\n",
    "   --runtime-version=1.4 \\\n",
    "   -- \\\n",
    "   --bucket=${BUCKET} \\\n",
    "   --output_dir=${OUTDIR} \\\n",
    "   --glove_embedding=gs://${BUCKET}/txtcls2/pretrained_embedding.txt.gz \\\n",
    "   --train_steps=36000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training finished with an accuracy of 54.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deploy trained model </h2>\n",
    "<p>\n",
    "Deploying the trained model to act as a REST web service is a simple gcloud call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-training-demos-ml/txtcls2/trained_model/export/Servo/\n",
      "gs://cloud-training-demos-ml/txtcls2/trained_model/export/Servo/1515526356/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/txtcls2/trained_model/export/Servo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"txtcls\"\n",
    "MODEL_VERSION=\"v2\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/txtcls1/trained_model/export/Servo/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "#gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Use model to predict </h2>\n",
    "<p>\n",
    "Send a JSON request to the endpoint of the service to make it predict which publication the article is more likely to run in. These are actual titles of articles in the New York Times, github, and TechCrunch on June 19.   These titles were not part of the training or evaluation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-01-09 21:44:07,479] {discovery.py:273} INFO - URL being requested: GET https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json\n",
      "[2018-01-09 21:44:07,657] {discovery.py:273} INFO - URL being requested: GET https://ml.googleapis.com/$discovery/rest?version=v1\n",
      "[2018-01-09 21:44:07,988] {discovery.py:863} INFO - URL being requested: POST https://ml.googleapis.com/v1/projects/cloud-training-demos/models/txtcls/versions/v2:predict?alt=json\n",
      "[2018-01-09 21:44:07,990] {client.py:614} INFO - Attempting refresh to obtain initial access_token\n",
      "[2018-01-09 21:44:07,991] {client.py:903} INFO - Refreshing access_token\n",
      "response={u'predictions': [{u'source': u'nytimes', u'prob': [0.8374465107917786, 0.04888102412223816, 0.11367242783308029], u'class': 0}, {u'source': u'github', u'prob': [0.012753208167850971, 0.987160325050354, 8.644349873065948e-05], u'class': 1}, {u'source': u'techcrunch', u'prob': [0.006752816028892994, 0.0005263009225018322, 0.992720901966095], u'class': 2}]}\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials,\n",
    "            discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json')\n",
    "\n",
    "request_data = {'instances':\n",
    "  [\n",
    "      {\n",
    "        'title': 'Supreme Court to Hear Major Case on Partisan Districts'.lower()\n",
    "      },\n",
    "      {\n",
    "        'title': 'Furan -- build and push Docker images from GitHub to target'.lower()\n",
    "      },\n",
    "      {\n",
    "        'title': 'Time Warner will spend $100M on Snapchat original shows and ads'.lower()\n",
    "      },\n",
    "  ]\n",
    "}\n",
    "\n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'txtcls', 'v2')\n",
    "response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "print \"response={0}\".format(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
